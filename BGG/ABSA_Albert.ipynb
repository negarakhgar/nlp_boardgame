{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/negarakhgar/Desktop/nlp project/data/english_boardgames_comments.csv'\n",
    "english_comments_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = { \n",
    "    'luck': ['luck', 'chance', 'random', 'alea'],\n",
    "    'bookkeeping': ['recording', 'bookkeeping', 'rulebook', 'manual', 'tracking', 'record'],\n",
    "    'downtime': ['downtime', 'waiting', 'idle', 'turn'],\n",
    "    'interaction': ['interaction', 'influence', 'impact', 'affect'],\n",
    "    'bash_the_leader': ['bash the leader', 'target the leader', 'attack the leader'],\n",
    "    'complexity': ['complicated', 'complex', 'rules', 'difficult', 'complex']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_albert = AlbertForSequenceClassification.from_pretrained('/Users/negarakhgar/Desktop/nlp project/model')\n",
    "tokenizer_albert = AlbertTokenizer.from_pretrained('/Users/negarakhgar/Desktop/nlp project/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertForSequenceClassification(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertSdpaAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting the mode to evaluation mode\n",
    "model_albert.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aspect extraction\n",
    "def extract_aspects(comment):\n",
    "    detected_aspects = []\n",
    "    for aspect, keywords in aspects.items():\n",
    "        if any(keyword in comment.lower() for keyword in keywords):\n",
    "            detected_aspects.append(aspect)\n",
    "    return detected_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying aspect extraction to each comment\n",
    "english_comments_df['detected_aspects'] = english_comments_df['value'].apply(extract_aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out comments that have detected aspects\n",
    "filtered_comments_df = english_comments_df[english_comments_df['detected_aspects'].map(len) > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absa_on_aspects(comment, detected_aspects):\n",
    "    aspect_sentiments = {}\n",
    "    for aspect in detected_aspects:\n",
    "        inputs = tokenizer_albert(comment, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "        inputs = {key: val for key, val in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model_albert(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "        labels = {0: 'negative', 1: 'positive'}\n",
    "        aspect_sentiments[aspect] = labels[predicted_class]\n",
    "\n",
    "    return aspect_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying ABSA to each comment with detected aspects\n",
    "filtered_comments_df['aspect_sentiments'] = filtered_comments_df.apply(\n",
    "    lambda row: absa_on_aspects(row['value'], row['detected_aspects']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "absa_results_file = '/Users/negarakhgar/Desktop/nlp project/boardgames_absa_results_albert.csv'\n",
    "filtered_comments_df.to_csv(absa_results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    boardgame_id                                              value  \\\n",
      "3         224517  Very clever game, enjoyable overall.  Plus poi...   \n",
      "4         224517  Brilliant!  Fits right into my wheelhouse all ...   \n",
      "7         224517  The game itself is not interesting enough to l...   \n",
      "9         224517  This is a near-perfect board game because...  ...   \n",
      "10        224517  Excellent and highly interactive game. Probabl...   \n",
      "\n",
      "                       detected_aspects  \\\n",
      "3   [downtime, interaction, complexity]   \n",
      "4                         [interaction]   \n",
      "7                         [interaction]   \n",
      "9             [interaction, complexity]   \n",
      "10  [downtime, interaction, complexity]   \n",
      "\n",
      "                                    aspect_sentiments  \n",
      "3   {'downtime': 'positive', 'interaction': 'posit...  \n",
      "4                         {'interaction': 'positive'}  \n",
      "7                         {'interaction': 'negative'}  \n",
      "9   {'interaction': 'positive', 'complexity': 'pos...  \n",
      "10  {'downtime': 'positive', 'interaction': 'posit...  \n",
      "ABSA completed and results saved to /Users/negarakhgar/Desktop/nlp project/boardgames_absa_results_albert.csv\n"
     ]
    }
   ],
   "source": [
    "print(filtered_comments_df[['boardgame_id', 'value', 'detected_aspects', 'aspect_sentiments']].head())\n",
    "\n",
    "print(f\"ABSA completed and results saved to {absa_results_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
